{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras_facenet import FaceNet\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# ----------------------------\n",
        "# 1. Prepare dataset\n",
        "# ----------------------------\n",
        "persons = {\n",
        "    \"Abhinav\": [\"/content/1000162666.jpg\", \"/content/abhtest.jpg\"],\n",
        "    \"Srikar\": [\"/content/1000162667.jpg\", \"/content/Pi7_Tool_Srikar_passport_photo.jpg\"],\n",
        "    \"Sukesh\": [\"/content/1000162665.jpg\", \"/content/suktest.jpg\"]\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Load FaceNet\n",
        "# ----------------------------\n",
        "embedder = FaceNet()\n",
        "\n",
        "def load_and_preprocess(img_path):\n",
        "    \"\"\"Load image and preprocess for FaceNet\"\"\"\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found or unreadable: {img_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def get_embedding(img_path):\n",
        "    \"\"\"Get 512-dim FaceNet embedding\"\"\"\n",
        "    img = load_and_preprocess(img_path)\n",
        "    embedding = embedder.embeddings([img])[0]\n",
        "    return embedding\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Build training data\n",
        "# ----------------------------\n",
        "X, y = [], []\n",
        "labels = list(persons.keys())\n",
        "\n",
        "for label in labels:\n",
        "    for img_path in persons[label]:\n",
        "        try:\n",
        "            emb = get_embedding(img_path)\n",
        "            X.append(emb)\n",
        "            y.append(label)\n",
        "        except Exception as e:\n",
        "            print(f\"⚠️ Skipping {img_path}: {e}\")\n",
        "\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "print(\"✅ Data prepared:\", X.shape, y.shape)\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Train One-vs-All classifiers\n",
        "# ----------------------------\n",
        "models = {}\n",
        "for label in labels:\n",
        "    binary_y = (y == label).astype(int)  # 1 for this person, 0 for others\n",
        "    clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
        "    clf.fit(X, binary_y)\n",
        "    models[label] = clf\n",
        "    joblib.dump(clf, f\"{label}_model.pkl\")\n",
        "    print(f\"💾 Saved model for {label}\")\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Prediction Function\n",
        "# ----------------------------\n",
        "def predict(img_path, models, threshold=0.3):\n",
        "    try:\n",
        "        emb = get_embedding(img_path).reshape(1, -1)\n",
        "    except Exception as e:\n",
        "        return \"Error\", str(e)\n",
        "\n",
        "    scores = {label: model.predict_proba(emb)[0][1] for label, model in models.items()}\n",
        "    best_label = max(scores, key=scores.get)\n",
        "    best_score = scores[best_label]\n",
        "\n",
        "    if best_score >= threshold:\n",
        "        return best_label, scores\n",
        "    else:\n",
        "        return \"Unknown\", scores\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Test predictions\n",
        "# ----------------------------\n",
        "for person, imgs in persons.items():\n",
        "    for test_img in imgs:\n",
        "        result = predict(test_img, models)\n",
        "        print(f\"🧪 {person} test: {result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3CS4Xm8CmJMV",
        "outputId": "e6e78d9b-0369-4b5b-9301-ce386275ab7f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "✅ Data prepared: (6, 512) (6,)\n",
            "💾 Saved model for Abhinav\n",
            "💾 Saved model for Srikar\n",
            "💾 Saved model for Sukesh\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step\n",
            "🧪 Abhinav test: ('Abhinav', {'Abhinav': np.float64(0.591450086448346), 'Srikar': np.float64(0.3980138640632825), 'Sukesh': np.float64(0.43071583658500584)})\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "🧪 Abhinav test: ('Abhinav', {'Abhinav': np.float64(0.5887685733212001), 'Srikar': np.float64(0.4097548538634941), 'Sukesh': np.float64(0.42158407965428396)})\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "🧪 Srikar test: ('Srikar', {'Abhinav': np.float64(0.4451725896570567), 'Srikar': np.float64(0.5659397788678654), 'Sukesh': np.float64(0.41042501896482975)})\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "🧪 Srikar test: ('Srikar', {'Abhinav': np.float64(0.35529653933474575), 'Srikar': np.float64(0.5902395217354187), 'Sukesh': np.float64(0.47469165588357526)})\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "🧪 Sukesh test: ('Sukesh', {'Abhinav': np.float64(0.5098718292907921), 'Srikar': np.float64(0.3615963720717627), 'Sukesh': np.float64(0.5542354763887455)})\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "🧪 Sukesh test: ('Sukesh', {'Abhinav': np.float64(0.3291727204036618), 'Srikar': np.float64(0.5179600769781326), 'Sukesh': np.float64(0.5772487619898995)})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "from keras_facenet import FaceNet\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import joblib\n",
        "\n",
        "# Training data\n",
        "persons = {\n",
        "    \"Abhinav\": [\"/content/1000162666.jpg\", \"/content/abhtest.jpg\"],\n",
        "    \"Srikar\": [\"/content/1000162667.jpg\", \"/content/Pi7_Tool_Srikar_passport_photo.jpg\"],\n",
        "    \"Sukesh\": [\"/content/1000162665.jpg\", \"/content/suktest.jpg\"]\n",
        "}\n",
        "\n",
        "# Load FaceNet\n",
        "embedder = FaceNet()\n",
        "\n",
        "def load_and_preprocess(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found: {img_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def get_embedding(img_path):\n",
        "    img = load_and_preprocess(img_path)\n",
        "    return embedder.embeddings([img])[0]\n",
        "\n",
        "# Prepare embeddings\n",
        "X, y = [], []\n",
        "labels = list(persons.keys())\n",
        "for label in labels:\n",
        "    for img_path in persons[label]:\n",
        "        emb = get_embedding(img_path)\n",
        "        X.append(emb)\n",
        "        y.append(label)\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "\n",
        "# Train one-vs-all logistic regression\n",
        "models = {}\n",
        "for label in labels:\n",
        "    binary_y = (y == label).astype(int)\n",
        "    clf = LogisticRegression(max_iter=1000, class_weight=\"balanced\")\n",
        "    clf.fit(X, binary_y)\n",
        "    models[label] = clf\n",
        "    joblib.dump(clf, f\"{label}_model.pkl\")\n",
        "\n",
        "# Save label list\n",
        "joblib.dump(labels, \"labels.pkl\")\n",
        "print(\"✅ Models and labels saved!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0C18FoQzmuCN",
        "outputId": "a6a29234-ccd8-4c6f-d392-849aa99f62dd"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "✅ Models and labels saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras_facenet import FaceNet\n",
        "\n",
        "# Load models\n",
        "labels = joblib.load(\"labels.pkl\")\n",
        "models = {label: joblib.load(f\"{label}_model.pkl\") for label in labels}\n",
        "\n",
        "# FaceNet embedder\n",
        "embedder = FaceNet()\n",
        "\n",
        "def load_and_preprocess(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise ValueError(f\"Image not found: {img_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "def get_embedding(img_path):\n",
        "    img = load_and_preprocess(img_path)\n",
        "    return embedder.embeddings([img])[0]\n",
        "\n",
        "def predict(img_path, models, threshold=0.3):\n",
        "    emb = get_embedding(img_path).reshape(1, -1)\n",
        "    scores = {label: model.predict_proba(emb)[0][1] for label, model in models.items()}\n",
        "    best_label = max(scores, key=scores.get)\n",
        "    best_score = scores[best_label]\n",
        "    if best_score >= threshold:\n",
        "        return best_label, scores\n",
        "    else:\n",
        "        return \"Unknown\", scores\n",
        "\n",
        "# Test\n",
        "test_img = \"/content/Pi7_Tool_Srikar_passport_photo.jpg\"  # replace with your path\n",
        "label, scores = predict(test_img, models)\n",
        "print(\"Prediction:\", label)\n",
        "print(\"Scores:\", scores)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50P9cHeqnCCZ",
        "outputId": "db5b91a9-127b-46b1-eac2-30ba6f9a1423"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 7s/step\n",
            "Prediction: Srikar\n",
            "Scores: {'Abhinav': np.float64(0.35529653933474575), 'Srikar': np.float64(0.5902395217354187), 'Sukesh': np.float64(0.47469165588357526)}\n"
          ]
        }
      ]
    }
  ]
}